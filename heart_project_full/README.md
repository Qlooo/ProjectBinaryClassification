
# Heart Prediction - Refactored ML Project

This repository was autogenerated from the Jupyter notebook `Heart_prediction.ipynb`.

## Project structure

```
heart_project/
├─ src/heart_pred/             # core package
│  ├─ __init__.py
│  ├─ data_preprocessing.py
│  ├─ model.py
│  └─ utils.py
├─ scripts/
│  ├─ train.py
│  └─ evaluate.py
├─ requirements.txt
└─ tests/
   └─ test_preprocessing.py
```

## Quickstart

1. Create virtual environment and install dependencies:

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

2. Run training:

```bash
python scripts/train.py --data path/to/your/heart.csv --target target --output-dir artifacts
```

3. Evaluate:

```bash
python scripts/evaluate.py --data path/to/your/heart.csv --model-path artifacts/model.joblib
```

## What's included

- Refactored code split into `data_preprocessing`, `model`, and `utils`.
- Simple training and evaluation scripts.
- `requirements.txt` with core dependencies.

## Next steps (suggested)

- Add unit tests and CI (a starter `tests/` is included).
- Add dvc pipeline for data and model versioning.
- Add linters (`black`, `flake8`, `isort`) and pre-commit hooks.
- Improve configuration management (e.g., `hydra`, `yaml` configs).



## Developer setup: linters, pre-commit, CI, DVC


### Linters & pre-commit
Install dev dependencies and enable pre-commit hooks:

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements-dev.txt
pre-commit install
pre-commit run --all-files
```

This repository includes configuration for `black`, `isort`, and `flake8`.

### Continuous Integration (GitHub Actions)
A CI workflow is included in `.github/workflows/ci.yml`. It will install dependencies, run linters, and run tests on push and PRs to `main`/`master`.

### DVC pipeline (skeleton)
A `dvc.yaml` pipeline skeleton is included with stages: `preprocess`, `train`, `evaluate`.

To use it locally (after installing dvc):

```bash
dvc init
dvc add data/raw/heart.csv
dvc repro
```

The pipeline expects your raw CSV at `data/raw/heart.csv` and will produce `data/processed/heart_processed.csv` and `artifacts/model.joblib`.
